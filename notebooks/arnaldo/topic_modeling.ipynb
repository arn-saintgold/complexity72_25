{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c489b50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnaldo/Documents/prog-projects/complexity72_25/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "from cuml.cluster import HDBSCAN as cHDBSCAN\n",
    "from cuml.manifold import UMAP as cUMAP\n",
    "from bertopic.dimensionality import BaseDimensionalityReduction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from bertopic.representation import MaximalMarginalRelevance\n",
    "from transformers import pipeline\n",
    "from bertopic.representation import TextGeneration\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b765dd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_id</th>\n",
       "      <th>quoted_id</th>\n",
       "      <th>replied_id</th>\n",
       "      <th>url</th>\n",
       "      <th>expanded_url</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>username</th>\n",
       "      <th>individual_or_org</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1399517402984062983</td>\n",
       "      <td>40955185</td>\n",
       "      <td>2021-06-01 00:05:25+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>What is the role on @NigeriaGov at the on goin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.399244e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://t.co/iAQsVvLDXp</td>\n",
       "      <td>https://twitter.com/COP26/status/1399244254162...</td>\n",
       "      <td>SB2021</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>OlumideIDOWU</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Activist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1399525678991626240</td>\n",
       "      <td>796572560821485570</td>\n",
       "      <td>2021-06-01 00:38:18+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Pressure is mounting on PM @ScottMorrisonMP ah...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://t.co/iZaZWgA5wW</td>\n",
       "      <td>https://twitter.com/ActOnClimateVic/status/139...</td>\n",
       "      <td>COP26 AusClimateSolutions Auspol</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>ActOnClimateVic</td>\n",
       "      <td>Organization</td>\n",
       "      <td>Activist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1399528606540337154</td>\n",
       "      <td>16220555</td>\n",
       "      <td>2021-06-01 00:49:56+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @MarkJCarney: Looking fwd to tomorrow’s fir...</td>\n",
       "      <td>1.399418e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>netzero</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ElizabethMay</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1399531766344474629</td>\n",
       "      <td>202313343</td>\n",
       "      <td>2021-06-01 01:02:29+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @UNFCCC: The May-June 2021 @UN Climate Chan...</td>\n",
       "      <td>1.399487e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>COP26</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WRIClimate</td>\n",
       "      <td>Organization</td>\n",
       "      <td>International Organization / NGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1399538862158929922</td>\n",
       "      <td>796572560821485570</td>\n",
       "      <td>2021-06-01 01:30:41+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Momentum is building in the lead up to #COP26....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://t.co/abIgpeslsx</td>\n",
       "      <td>https://www.canberratimes.com.au/story/7277689...</td>\n",
       "      <td>COP26 AusClimateSolutions Auspol</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>ActOnClimateVic</td>\n",
       "      <td>Organization</td>\n",
       "      <td>Activist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           author_id                created_at lang  \\\n",
       "0  1399517402984062983            40955185 2021-06-01 00:05:25+00:00   en   \n",
       "1  1399525678991626240  796572560821485570 2021-06-01 00:38:18+00:00   en   \n",
       "2  1399528606540337154            16220555 2021-06-01 00:49:56+00:00   en   \n",
       "3  1399531766344474629           202313343 2021-06-01 01:02:29+00:00   en   \n",
       "4  1399538862158929922  796572560821485570 2021-06-01 01:30:41+00:00   en   \n",
       "\n",
       "                                                text  retweeted_id  \\\n",
       "0  What is the role on @NigeriaGov at the on goin...           NaN   \n",
       "1  Pressure is mounting on PM @ScottMorrisonMP ah...           NaN   \n",
       "2  RT @MarkJCarney: Looking fwd to tomorrow’s fir...  1.399418e+18   \n",
       "3  RT @UNFCCC: The May-June 2021 @UN Climate Chan...  1.399487e+18   \n",
       "4  Momentum is building in the lead up to #COP26....           NaN   \n",
       "\n",
       "      quoted_id  replied_id                      url  \\\n",
       "0  1.399244e+18         NaN  https://t.co/iAQsVvLDXp   \n",
       "1           NaN         NaN  https://t.co/iZaZWgA5wW   \n",
       "2           NaN         NaN                            \n",
       "3           NaN         NaN                            \n",
       "4           NaN         NaN  https://t.co/abIgpeslsx   \n",
       "\n",
       "                                        expanded_url  \\\n",
       "0  https://twitter.com/COP26/status/1399244254162...   \n",
       "1  https://twitter.com/ActOnClimateVic/status/139...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  https://www.canberratimes.com.au/story/7277689...   \n",
       "\n",
       "                           hashtags  retweet_count  reply_count  like_count  \\\n",
       "0                            SB2021              4            1           7   \n",
       "1  COP26 AusClimateSolutions Auspol             21            0          15   \n",
       "2                           netzero             27            0           0   \n",
       "3                             COP26             46            0           0   \n",
       "4  COP26 AusClimateSolutions Auspol              1            0           2   \n",
       "\n",
       "   quote_count         username individual_or_org  \\\n",
       "0            0     OlumideIDOWU        Individual   \n",
       "1            0  ActOnClimateVic      Organization   \n",
       "2            0     ElizabethMay        Individual   \n",
       "3            0       WRIClimate      Organization   \n",
       "4            0  ActOnClimateVic      Organization   \n",
       "\n",
       "                           category  \n",
       "0                          Activist  \n",
       "1                          Activist  \n",
       "2                          Politics  \n",
       "3  International Organization / NGO  \n",
       "4                          Activist  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"./../../data/raw/cop26_tweets_en.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8316911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precompute embeddings\n",
    "#embeddings = topic_model.embedding_model.encode(documents, show_progress_bar=True, )\n",
    "# save embeddings\n",
    "#np.save(\"../../data/processed/cop26_tweets_en.parquet.npy\", embeddings)\n",
    "embeddings = np.load('./../../data/processed/cop26_tweets_en.parquet.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e33c14b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 12998\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "duplicates = embeddings.shape[0] - np.unique(embeddings, axis=0).shape[0]\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7e079fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105016\n"
     ]
    }
   ],
   "source": [
    "unique_rows = df[df['text'].map(df['text'].value_counts()) == 1]\n",
    "unique_mask = df['text'].map(df['text'].value_counts()) == 1\n",
    "\n",
    "# Select corresponding rows from the embeddings array\n",
    "unique_embeddings = embeddings[unique_mask.to_numpy()]\n",
    "unique_documents = unique_rows['text']\n",
    "print(len(unique_documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5864e9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = cUMAP(n_components=5, min_dist=0.0, metric='cosine')\n",
    "#reduced_embeddings = umap_model.fit_transform(unique_embeddings)\n",
    "hdbscan_model = cHDBSCAN(min_cluster_size=15, metric='euclidean', cluster_selection_method='eom', prediction_data=True )\n",
    "#clustering = hdbscan_model.fit_predict(reduced_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdf91e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fast_hdbscan\n",
    "umap_model = UMAP(n_components=5, n_neighbors=15, n_jobs=-1, metric='cosine')\n",
    "hdbscan_model = fast_hdbscan.HDBSCAN(min_cluster_size=15, metric='euclidean', cluster_selection_method='eom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0711b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_documents = unique_documents.to_list()[:1000]\n",
    "subset_embeddings = unique_embeddings[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35b78e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the BERTopic model\n",
    "topic_model = BERTopic(\n",
    "    vectorizer_model=CountVectorizer(ngram_range=(1, 2), stop_words='english'),\n",
    "    #representation_model=KeyBERTInspired(),\n",
    "    hdbscan_model = hdbscan_model,\n",
    "    umap_model=umap_model,\n",
    "\n",
    "    #hdbscan_model=HDBSCAN(min_cluster_size=100, metric='euclidean', cluster_selection_method='eom', prediction_data=False),\n",
    "    verbose=True,\n",
    "    calculate_probabilities=True,\n",
    "    language='english',\n",
    "    embedding_model=SentenceTransformer('all-MiniLM-L6-v2'),\n",
    "    #dimensionality_reduction_model=BaseDimensionalityReduction(n_components=5),\n",
    "    ctfidf_model=ClassTfidfTransformer(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e38f685",
   "metadata": {},
   "source": [
    "### Parallel HDBSCAN, 1K Docs\n",
    "Works. It runs in 4 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "298b9c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 15:01:56,565 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-06-30 15:02:00,555 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-06-30 15:02:00,556 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-06-30 15:02:00,561 - BERTopic - Cluster - Completed ✓\n",
      "2025-06-30 15:02:00,562 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2025-06-30 15:02:00,602 - BERTopic - Representation - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "topics, probs = topic_model.fit_transform(documents=subset_documents, embeddings=subset_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee10cb8",
   "metadata": {},
   "source": [
    "### Parallel HDBSCAN 10K Docs\n",
    "It takes ~1 minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9316e47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 15:02:32,300 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-06-30 15:03:18,927 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-06-30 15:03:18,930 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-06-30 15:03:19,343 - BERTopic - Cluster - Completed ✓\n",
      "2025-06-30 15:03:19,359 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2025-06-30 15:03:24,025 - BERTopic - Representation - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "topics, probs = topic_model.fit_transform(documents=unique_documents, embeddings=unique_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614e240e",
   "metadata": {},
   "source": [
    "### Evaluate parallel HDBSCAN\n",
    "Which metric can be used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4ce935",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HDBSCAN' object has no attribute 'core_dist_n_jobs'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtopic_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhdbscan_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcore_dist_n_jobs\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'HDBSCAN' object has no attribute 'core_dist_n_jobs'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d55e9091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      "{'min_cluster_size': 50, 'cluster_selection_method': 'leaf', 'silhouette_score': 0.759192054001691}\n",
      "\n",
      "All Results:\n",
      "min_cluster_size=15, method=eom, silhouette=0.7300\n",
      "min_cluster_size=15, method=leaf, silhouette=0.7409\n",
      "min_cluster_size=50, method=eom, silhouette=0.7355\n",
      "min_cluster_size=50, method=leaf, silhouette=0.7592\n",
      "min_cluster_size=100, method=eom, silhouette=0.5903\n",
      "min_cluster_size=100, method=leaf, silhouette=0.7443\n"
     ]
    }
   ],
   "source": [
    "import cuml\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "from cuml.cluster import HDBSCAN\n",
    "from cuml.metrics import pairwise_distances\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Sample data (replace with your own GPU-compatible input)\n",
    "X_np, _ = make_blobs(n_samples=1000, centers=5, cluster_std=1.0, random_state=42)\n",
    "X = cp.asarray(X_np)\n",
    "\n",
    "def evaluate_hdbscan(X, min_cluster_sizes, methods):\n",
    "    best_score = -1\n",
    "    best_params = {}\n",
    "    results = []\n",
    "\n",
    "    for min_size in min_cluster_sizes:\n",
    "        for method in methods:\n",
    "            try:\n",
    "                clusterer = HDBSCAN(min_cluster_size=min_size,\n",
    "                                    cluster_selection_method=method)\n",
    "                clusterer.fit(X)\n",
    "                labels = clusterer.labels_\n",
    "                mask = labels != -1\n",
    "                filtered_labels = cp.asnumpy(labels[mask])\n",
    "\n",
    "                if filtered_labels.size < 2 or len(set(filtered_labels)) < 2:\n",
    "                    continue\n",
    "\n",
    "\n",
    "                # Compute pairwise distances (on GPU)\n",
    "                # Compute pairwise distances and convert to CPU\n",
    "                dists_gpu = pairwise_distances(X[mask])\n",
    "                dists_cpu = dists_gpu.get()\n",
    "\n",
    "                # Convert labels to CPU\n",
    "                labels_cpu = cp.asnumpy(labels[mask])\n",
    "\n",
    "                # Compute silhouette score\n",
    "                sil_score = silhouette_score(dists_cpu, labels_cpu, metric='precomputed')\n",
    "\n",
    "                results.append((min_size, method, sil_score))\n",
    "\n",
    "                if sil_score > best_score:\n",
    "                    best_score = sil_score\n",
    "                    best_params = {\n",
    "                        'min_cluster_size': min_size,\n",
    "                        'cluster_selection_method': method,\n",
    "                        'silhouette_score': sil_score\n",
    "                    }\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed for min_size={min_size}, method={method}: {e}\")\n",
    "\n",
    "    return best_params, results\n",
    "\n",
    "# Parameter ranges\n",
    "min_cluster_sizes = [15, 50, 100]\n",
    "cluster_methods = ['eom', 'leaf']\n",
    "\n",
    "best_config, all_results = evaluate_hdbscan(X, min_cluster_sizes, cluster_methods)\n",
    "\n",
    "print(\"Best Parameters:\")\n",
    "print(best_config)\n",
    "print(\"\\nAll Results:\")\n",
    "for res in all_results:\n",
    "    print(f\"min_cluster_size={res[0]}, method={res[1]}, silhouette={res[2]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf47410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed for min_size=15, method=eom: std::bad_alloc: out_of_memory: CUDA error (failed to allocate 11175872656 bytes) at: /tmp/pip-build-env-y7l1nuix/normal/lib/python3.12/site-packages/librmm/include/rmm/mr/device/cuda_memory_resource.hpp:62: cudaErrorMemoryAllocation out of memory\n"
     ]
    }
   ],
   "source": [
    "#reduced_embeddings.shape\n",
    "evaluate_hdbscan(reduced_embeddings, min_cluster_sizes, cluster_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a23c7849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Cluster Persistence Score: 1.000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get labels and persistence scores\n",
    "labels = hdbscan_model.labels_\n",
    "persistence = hdbscan_model.cluster_persistence_  # shape: (n_clusters,)\n",
    "persistence = np.squeeze(persistence)\n",
    "valid_clusters = np.unique(labels)\n",
    "valid_clusters = valid_clusters[valid_clusters != -1]  # Exclude noise (-1)\n",
    "# Compute sizes of valid clusters only (in same order as persistence)\n",
    "cluster_sizes = np.array([np.sum(labels == cluster_id) for cluster_id in valid_clusters])\n",
    "\n",
    "# Now compute weighted average\n",
    "weighted_persistence_score = np.average(persistence, weights=cluster_sizes)\n",
    "\n",
    "print(f\"Weighted Cluster Persistence Score: {weighted_persistence_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65d235c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "from cuml.cluster import HDBSCAN\n",
    "\n",
    "def find_best_hdbscan_params_by_noise_ratio(X, min_cluster_sizes, methods):\n",
    "    best_ratio = float('inf')\n",
    "    best_params = {}\n",
    "    results = []\n",
    "\n",
    "    for min_size in min_cluster_sizes:\n",
    "        for method in methods:\n",
    "            try:\n",
    "                clusterer = HDBSCAN(min_cluster_size=min_size,\n",
    "                                    cluster_selection_method=method)\n",
    "                clusterer.fit(X)\n",
    "                labels = clusterer.labels_\n",
    "\n",
    "                labels_cpu = cp.asnumpy(labels)\n",
    "                num_noise = (labels_cpu == -1).sum()\n",
    "                unique_clusters = set(labels_cpu) - {-1}\n",
    "                num_clusters = len(unique_clusters)\n",
    "\n",
    "                if num_clusters == 0:\n",
    "                    continue  # skip all-noise results\n",
    "\n",
    "                ratio = num_noise / num_clusters\n",
    "                results.append((min_size, method, num_noise, num_clusters, ratio))\n",
    "\n",
    "                if ratio < best_ratio:\n",
    "                    best_ratio = ratio\n",
    "                    best_params = {\n",
    "                        'min_cluster_size': min_size,\n",
    "                        'cluster_selection_method': method,\n",
    "                        'noise_points': num_noise,\n",
    "                        'num_clusters': num_clusters,\n",
    "                        'noise_to_cluster_ratio': ratio\n",
    "                    }\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error for min_size={min_size}, method={method}: {e}\")\n",
    "                continue\n",
    "\n",
    "    return best_params, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8436b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (by noise-to-cluster ratio):\n",
      "{'min_cluster_size': 5, 'cluster_selection_method': 'eom', 'noise_points': np.int64(50702), 'num_clusters': 2101, 'noise_to_cluster_ratio': np.float64(24.13231794383627)}\n",
      "\n",
      "All Results:\n",
      "min_cluster_size=5, method=eom, noise=50702, clusters=2101, ratio=24.1323\n",
      "min_cluster_size=5, method=leaf, noise=68436, clusters=2676, ratio=25.5740\n",
      "min_cluster_size=10, method=eom, noise=50413, clusters=878, ratio=57.4180\n",
      "min_cluster_size=10, method=leaf, noise=68403, clusters=1107, ratio=61.7913\n",
      "min_cluster_size=20, method=eom, noise=49244, clusters=399, ratio=123.4185\n",
      "min_cluster_size=20, method=leaf, noise=66142, clusters=509, ratio=129.9450\n",
      "min_cluster_size=50, method=eom, noise=48862, clusters=171, ratio=285.7427\n",
      "min_cluster_size=50, method=leaf, noise=62244, clusters=205, ratio=303.6293\n"
     ]
    }
   ],
   "source": [
    "min_cluster_sizes = [5, 10, 20, 50]\n",
    "cluster_methods = ['eom', 'leaf']\n",
    "best_config, all_results = find_best_hdbscan_params_by_noise_ratio(reduced_embeddings, min_cluster_sizes, cluster_methods)\n",
    "\n",
    "print(\"Best Parameters (by noise-to-cluster ratio):\")\n",
    "print(best_config)\n",
    "\n",
    "print(\"\\nAll Results:\")\n",
    "for res in all_results:\n",
    "    print(f\"min_cluster_size={res[0]}, method={res[1]}, noise={res[2]}, clusters={res[3]}, ratio={res[4]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f85f77c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+git://github.com/milesgranger/gap_statistic.git\n",
      "  Cloning git://github.com/milesgranger/gap_statistic.git to /tmp/pip-req-build-kx_r77bw\n",
      "  Running command git clone --filter=blob:none --quiet git://github.com/milesgranger/gap_statistic.git /tmp/pip-req-build-kx_r77bw\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/arnaldo/Documents/prog-projects/complexity72_25/.venv/lib/python3.12/site-packages (24.0)\n",
      "Collecting pip\n",
      "  Using cached pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement install (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for install\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gap_statistic'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m get_ipython().system(\u001b[33m'\u001b[39m\u001b[33mpip install git+git://github.com/milesgranger/gap_statistic.git\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m get_ipython().system(\u001b[33m'\u001b[39m\u001b[33mpip install pip install --upgrade gap-stat\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgap_statistic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OptimalK\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimal_kmeans\u001b[39m(data, max_k=\u001b[32m20\u001b[39m):\n\u001b[32m      6\u001b[39m     optimalK = OptimalK(parallel_backend=\u001b[33m'\u001b[39m\u001b[33mjoblib\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'gap_statistic'"
     ]
    }
   ],
   "source": [
    "!pip install git+git://github.com/milesgranger/gap_statistic.git\n",
    "!pip install pip install --upgrade gap-stat\n",
    "\n",
    "from gap_statistic import OptimalK\n",
    "def optimal_kmeans(data, max_k=20):\n",
    "    optimalK = OptimalK(parallel_backend='joblib')\n",
    "    n_clusters = optimalK(data, cluster_array=np.arange(1, max_k))\n",
    "    return MiniBatchKMeans(n_clusters=n_clusters, batch_size=256).fit(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2522aff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1852b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: n_neighbors=15, n_components=50, min_cluster_size=20, cluster_selection_method=eom, max_relative_validity=0.3250034743468451\n"
     ]
    }
   ],
   "source": [
    "# pick the hdbscan and umap parameters which improve the relative_validity_ \n",
    "max_relative_validity = 0\n",
    "best_params = None\n",
    "for n_neighbors in [15, 50]:\n",
    "    for n_components in [2, 5, 10, 20, 50]:\n",
    "        umap_model = UMAP(n_neighbors=n_neighbors, n_components=n_components, min_dist=0.0, metric='cosine')\n",
    "        reduced_embeddings = umap_model.fit_transform(embeddings)\n",
    "        for min_cluster_size in [10, 20, 50, 100, 200, 500]:\n",
    "            for cluster_selection_method in ['eom', 'leaf']:\n",
    "                hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size, metric='euclidean', cluster_selection_method=cluster_selection_method, prediction_data=True, gen_min_span_tree=True)\n",
    "                relative_validity = hdbscan_model.fit(reduced_embeddings).relative_validity_\n",
    "                if relative_validity > max_relative_validity:\n",
    "                    max_relative_validity = relative_validity\n",
    "                    best_params = (n_neighbors, n_components, min_cluster_size, cluster_selection_method,)\n",
    "print(f\"Best parameters: n_neighbors={best_params[0]}, n_components={best_params[1]}, min_cluster_size={best_params[2]}, cluster_selection_method={best_params[3]}, max_relative_validity={max_relative_validity}\")\n",
    "umap_model = UMAP(n_neighbors=best_params[0], n_components=best_params[1], min_dist=0.0, metric='cosine')\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=best_params[2], metric='euclidean', cluster_selection_method=best_params[3], prediction_data=True, gen_min_span_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c633f101",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = [15, 5, 15, 'eom']\n",
    "umap_model = UMAP(n_neighbors=best_params[0], n_components=best_params[1], min_dist=0.0, metric='cosine')\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=best_params[2], metric='euclidean', cluster_selection_method=best_params[3], prediction_data=True, gen_min_span_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4accfa1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 16:17:14,947 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-06-26 16:18:14,906 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-06-26 16:18:14,908 - BERTopic - Cluster - Start clustering the reduced embeddings\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fit the model to the documents and embeddings\n",
    "topic_model.umap_model = umap_model\n",
    "topic_model.hdbscan_model = hdbscan_model\n",
    "topics, probabilities = topic_model.fit_transform(documents, embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca52919a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "#D55E00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.015610307413208627,
          0.018184403308885537,
          0.018721808016979126,
          0.026855984200560703,
          0.03062049697009241
         ],
         "xaxis": "x",
         "y": [
          "energy  ",
          "russia  ",
          "oil  ",
          "gas  ",
          "sanctions  "
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "#0072B2"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.013028466290045271,
          0.013093811750135258,
          0.019239412680790657,
          0.02995928294351247,
          0.035962129762785795
         ],
         "xaxis": "x2",
         "y": [
          "died  ",
          "old  ",
          "injured  ",
          "children  ",
          "killed  "
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "#CC79A7"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.010175024431450156,
          0.010387125233053969,
          0.010739511903663195,
          0.012745102034583103,
          0.05670620155382625
         ],
         "xaxis": "x3",
         "y": [
          "hope removing  ",
          "war  ",
          "putin power  ",
          "rt  ",
          "putin  "
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "#E69F00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.017465549025186808,
          0.017871039243371595,
          0.019580284818307498,
          0.03746240929727137,
          0.04982831884550923
         ],
         "xaxis": "x4",
         "y": [
          "ports  ",
          "port  ",
          "global  ",
          "food  ",
          "grain  "
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "#56B4E9"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.013959070577407312,
          0.01625870637422314,
          0.017077235559517817,
          0.0247296877758769,
          0.025991914705310433
         ],
         "xaxis": "x5",
         "y": [
          "shot  ",
          "air  ",
          "russian  ",
          "missiles  ",
          "missile  "
         ],
         "yaxis": "y5"
        },
        {
         "marker": {
          "color": "#009E73"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.017314786428192102,
          0.021053617912834888,
          0.021818087882220224,
          0.025534999879127145,
          0.04814154367272168
         ],
         "xaxis": "x6",
         "y": [
          "poland  ",
          "lies  ",
          "disinformation  ",
          "propaganda  ",
          "kremlin  "
         ],
         "yaxis": "y6"
        },
        {
         "marker": {
          "color": "#F0E442"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.013113107975841493,
          0.013571677140564387,
          0.013720970284129554,
          0.013822756437319537,
          0.07235778285567304
         ],
         "xaxis": "x7",
         "y": [
          "eastern flank  ",
          "alliance  ",
          "defence  ",
          "jensstoltenberg  ",
          "nato  "
         ],
         "yaxis": "y7"
        },
        {
         "marker": {
          "color": "#D55E00"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.017696387475244543,
          0.01804829960653413,
          0.022666192385987122,
          0.02301137995933175,
          0.02603251050377779
         ],
         "xaxis": "x8",
         "y": [
          "victory  ",
          "ukrainian  ",
          "flag  ",
          "standwithukraine  ",
          "glory  "
         ],
         "yaxis": "y8"
        },
        {
         "marker": {
          "color": "#0072B2"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.009686605916028245,
          0.010986504080724303,
          0.01805406481445041,
          0.019490609588547085,
          0.02360355781122817
         ],
         "xaxis": "x9",
         "y": [
          "rt  ",
          "war ukraine  ",
          "russia  ",
          "war  ",
          "ukraine  "
         ],
         "yaxis": "y9"
        },
        {
         "marker": {
          "color": "#CC79A7"
         },
         "orientation": "h",
         "type": "bar",
         "x": [
          0.01942371271276133,
          0.03138428211526213,
          0.03221332858567588,
          0.03530238634672508,
          0.05062742057753678
         ],
         "xaxis": "x10",
         "y": [
          "russian  ",
          "russian forces  ",
          "forces  ",
          "bridge  ",
          "kherson  "
         ],
         "yaxis": "y10"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 0",
          "x": 0.0875,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 1",
          "x": 0.36250000000000004,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 2",
          "x": 0.6375000000000001,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 3",
          "x": 0.9125,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 4",
          "x": 0.0875,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.6222222222222222,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 5",
          "x": 0.36250000000000004,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.6222222222222222,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 6",
          "x": 0.6375000000000001,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.6222222222222222,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 7",
          "x": 0.9125,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.6222222222222222,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 8",
          "x": 0.0875,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.24444444444444446,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Topic 9",
          "x": 0.36250000000000004,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.24444444444444446,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 750,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "Topic Word Scores",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.175
         ],
         "showgrid": true
        },
        "xaxis10": {
         "anchor": "y10",
         "domain": [
          0.275,
          0.45
         ],
         "showgrid": true
        },
        "xaxis11": {
         "anchor": "y11",
         "domain": [
          0.55,
          0.7250000000000001
         ],
         "showgrid": true
        },
        "xaxis12": {
         "anchor": "y12",
         "domain": [
          0.825,
          1
         ],
         "showgrid": true
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.275,
          0.45
         ],
         "showgrid": true
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.55,
          0.7250000000000001
         ],
         "showgrid": true
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.825,
          1
         ],
         "showgrid": true
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0,
          0.175
         ],
         "showgrid": true
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.275,
          0.45
         ],
         "showgrid": true
        },
        "xaxis7": {
         "anchor": "y7",
         "domain": [
          0.55,
          0.7250000000000001
         ],
         "showgrid": true
        },
        "xaxis8": {
         "anchor": "y8",
         "domain": [
          0.825,
          1
         ],
         "showgrid": true
        },
        "xaxis9": {
         "anchor": "y9",
         "domain": [
          0,
          0.175
         ],
         "showgrid": true
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.7555555555555555,
          1
         ],
         "showgrid": true
        },
        "yaxis10": {
         "anchor": "x10",
         "domain": [
          0,
          0.24444444444444446
         ],
         "showgrid": true
        },
        "yaxis11": {
         "anchor": "x11",
         "domain": [
          0,
          0.24444444444444446
         ],
         "showgrid": true
        },
        "yaxis12": {
         "anchor": "x12",
         "domain": [
          0,
          0.24444444444444446
         ],
         "showgrid": true
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.7555555555555555,
          1
         ],
         "showgrid": true
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0.7555555555555555,
          1
         ],
         "showgrid": true
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0.7555555555555555,
          1
         ],
         "showgrid": true
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0.37777777777777777,
          0.6222222222222222
         ],
         "showgrid": true
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0.37777777777777777,
          0.6222222222222222
         ],
         "showgrid": true
        },
        "yaxis7": {
         "anchor": "x7",
         "domain": [
          0.37777777777777777,
          0.6222222222222222
         ],
         "showgrid": true
        },
        "yaxis8": {
         "anchor": "x8",
         "domain": [
          0.37777777777777777,
          0.6222222222222222
         ],
         "showgrid": true
        },
        "yaxis9": {
         "anchor": "x9",
         "domain": [
          0,
          0.24444444444444446
         ],
         "showgrid": true
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the barchart of topics\n",
    "topic_model.visualize_barchart(top_n_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93d33fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>4630</td>\n",
       "      <td>-1_rt_ukraine_https_russia</td>\n",
       "      <td>[rt, ukraine, https, russia, russian, ukrainia...</td>\n",
       "      <td>[President Biden of Russian President Vladimir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>449</td>\n",
       "      <td>0_sanctions_gas_oil_russia</td>\n",
       "      <td>[sanctions, gas, oil, russia, energy, sanction...</td>\n",
       "      <td>[Putin continues to use energy as a weapon.\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>1_killed_children_injured_old</td>\n",
       "      <td>[killed, children, injured, old, died, wounded...</td>\n",
       "      <td>[Prosecutor General's Office daily update: rus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>238</td>\n",
       "      <td>2_putin_rt_putin power_war</td>\n",
       "      <td>[putin, rt, putin power, war, hope removing, s...</td>\n",
       "      <td>[@Independent My thoughts on how to penetrate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>223</td>\n",
       "      <td>3_grain_food_global_port</td>\n",
       "      <td>[grain, food, global, port, ports, global food...</td>\n",
       "      <td>[Russian missiles struck Odesa’s port on Satur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>62</td>\n",
       "      <td>23</td>\n",
       "      <td>62_losses_combat losses_estimates_indicative</td>\n",
       "      <td>[losses, combat losses, estimates, indicative,...</td>\n",
       "      <td>[RT @KyivIndependent: These are the indicative...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>63</td>\n",
       "      <td>23</td>\n",
       "      <td>63_russian navy_navy_sinking moskva_sinking</td>\n",
       "      <td>[russian navy, navy, sinking moskva, sinking, ...</td>\n",
       "      <td>[@Conflicts Not surprising that the Russian Na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>64</td>\n",
       "      <td>23</td>\n",
       "      <td>64_rada_verkhovna rada_verkhovna_rada ukraine</td>\n",
       "      <td>[rada, verkhovna rada, verkhovna, rada ukraine...</td>\n",
       "      <td>[Speaker of the Verkhovna Rada of #Ukraine @r_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>65</td>\n",
       "      <td>22</td>\n",
       "      <td>65_russian comrades_rebel russian_comrades_com...</td>\n",
       "      <td>[russian comrades, rebel russian, comrades, co...</td>\n",
       "      <td>[@SamRamani2 I think only the Russian people c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>66</td>\n",
       "      <td>22</td>\n",
       "      <td>66_germany_scholz_german_spd</td>\n",
       "      <td>[germany, scholz, german, spd, democratic, vis...</td>\n",
       "      <td>[By doublespeak, hypocrisy &amp;amp; sabotage of a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                               Name  \\\n",
       "0      -1   4630                         -1_rt_ukraine_https_russia   \n",
       "1       0    449                         0_sanctions_gas_oil_russia   \n",
       "2       1    250                      1_killed_children_injured_old   \n",
       "3       2    238                         2_putin_rt_putin power_war   \n",
       "4       3    223                           3_grain_food_global_port   \n",
       "..    ...    ...                                                ...   \n",
       "63     62     23       62_losses_combat losses_estimates_indicative   \n",
       "64     63     23        63_russian navy_navy_sinking moskva_sinking   \n",
       "65     64     23      64_rada_verkhovna rada_verkhovna_rada ukraine   \n",
       "66     65     22  65_russian comrades_rebel russian_comrades_com...   \n",
       "67     66     22                       66_germany_scholz_german_spd   \n",
       "\n",
       "                                       Representation  \\\n",
       "0   [rt, ukraine, https, russia, russian, ukrainia...   \n",
       "1   [sanctions, gas, oil, russia, energy, sanction...   \n",
       "2   [killed, children, injured, old, died, wounded...   \n",
       "3   [putin, rt, putin power, war, hope removing, s...   \n",
       "4   [grain, food, global, port, ports, global food...   \n",
       "..                                                ...   \n",
       "63  [losses, combat losses, estimates, indicative,...   \n",
       "64  [russian navy, navy, sinking moskva, sinking, ...   \n",
       "65  [rada, verkhovna rada, verkhovna, rada ukraine...   \n",
       "66  [russian comrades, rebel russian, comrades, co...   \n",
       "67  [germany, scholz, german, spd, democratic, vis...   \n",
       "\n",
       "                                  Representative_Docs  \n",
       "0   [President Biden of Russian President Vladimir...  \n",
       "1   [Putin continues to use energy as a weapon.\\n\\...  \n",
       "2   [Prosecutor General's Office daily update: rus...  \n",
       "3   [@Independent My thoughts on how to penetrate ...  \n",
       "4   [Russian missiles struck Odesa’s port on Satur...  \n",
       "..                                                ...  \n",
       "63  [RT @KyivIndependent: These are the indicative...  \n",
       "64  [@Conflicts Not surprising that the Russian Na...  \n",
       "65  [Speaker of the Verkhovna Rada of #Ukraine @r_...  \n",
       "66  [@SamRamani2 I think only the Russian people c...  \n",
       "67  [By doublespeak, hypocrisy &amp; sabotage of a...  \n",
       "\n",
       "[68 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe with topics\n",
    "topics_df = topic_model.get_topic_info()\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bd4931",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "topics_over_time = topic_model.topics_over_time(documents, timestamps,\n",
    "                                                global_tuning=True, evolution_tuning=True, nr_bins=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "504ff7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of months passed: 12\n"
     ]
    }
   ],
   "source": [
    "def count_months_passed(df, col_name):\n",
    "\n",
    "\n",
    "    df[col_name] = pd.to_datetime(df[col_name])\n",
    "\n",
    "    min_date = df[col_name].min()\n",
    "    max_date = df[col_name].max()\n",
    "\n",
    "# Calculate months difference\n",
    "    months_passed = (max_date.year - min_date.year) * 12 + (max_date.month - min_date.month)\n",
    "    return(months_passed)\n",
    "months_passed = count_months_passed(df, 'created_at')\n",
    "print(f\"Number of months passed: {months_passed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78f60137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>text</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>retweeted_id</th>\n",
       "      <th>...</th>\n",
       "      <th>expanded_url</th>\n",
       "      <th>mention_name</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>username</th>\n",
       "      <th>individual_or_org</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1546962934294888449</td>\n",
       "      <td>1424639970</td>\n",
       "      <td>2022-07-12T21:01:19.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>1546962934294888449</td>\n",
       "      <td>Selling drones to Russia would be a big win fo...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>https://edition.cnn.com/europe/live-news/russi...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>IuliiaMendel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1546967009493139456</td>\n",
       "      <td>1424639970</td>\n",
       "      <td>2022-07-12T21:17:30.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>1546967009493139456</td>\n",
       "      <td>Last month, Ukrainian prosecutors launched the...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>218</td>\n",
       "      <td>3</td>\n",
       "      <td>IuliiaMendel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1546968380602830850</td>\n",
       "      <td>1106777071</td>\n",
       "      <td>2022-07-12T21:22:57.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>1462548977367359490</td>\n",
       "      <td>1546960688899395585</td>\n",
       "      <td>@KyivIndependent My take on how Soviet hubris ...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>https://realcontextnews.com/moscows-1939-finla...</td>\n",
       "      <td>KyivIndependent</td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>bfry1981</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1546968414098538499</td>\n",
       "      <td>1106777071</td>\n",
       "      <td>2022-07-12T21:23:05.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>1546968414098538499</td>\n",
       "      <td>My take on how Soviet hubris in Finland in 193...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>https://realcontextnews.com/moscows-1939-finla...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>bfry1981</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1546969311130144768</td>\n",
       "      <td>1106777071</td>\n",
       "      <td>2022-07-12T21:26:39.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>4970411</td>\n",
       "      <td>1546966420046635008</td>\n",
       "      <td>@AJEnglish I've been saying for some time that...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>https://realcontextnews.com/how-ukraine-can-ta...</td>\n",
       "      <td>AJEnglish</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bfry1981</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id   author_id                created_at lang  \\\n",
       "5   1546962934294888449  1424639970  2022-07-12T21:01:19.000Z   en   \n",
       "38  1546967009493139456  1424639970  2022-07-12T21:17:30.000Z   en   \n",
       "50  1546968380602830850  1106777071  2022-07-12T21:22:57.000Z   en   \n",
       "53  1546968414098538499  1106777071  2022-07-12T21:23:05.000Z   en   \n",
       "74  1546969311130144768  1106777071  2022-07-12T21:26:39.000Z   en   \n",
       "\n",
       "    in_reply_to_user_id      conversation_id  \\\n",
       "5                        1546962934294888449   \n",
       "38                       1546967009493139456   \n",
       "50  1462548977367359490  1546960688899395585   \n",
       "53                       1546968414098538499   \n",
       "74              4970411  1546966420046635008   \n",
       "\n",
       "                                                 text reply_settings  \\\n",
       "5   Selling drones to Russia would be a big win fo...       everyone   \n",
       "38  Last month, Ukrainian prosecutors launched the...       everyone   \n",
       "50  @KyivIndependent My take on how Soviet hubris ...       everyone   \n",
       "53  My take on how Soviet hubris in Finland in 193...       everyone   \n",
       "74  @AJEnglish I've been saying for some time that...       everyone   \n",
       "\n",
       "   possibly_sensitive retweeted_id  ...  \\\n",
       "5               False               ...   \n",
       "38              False               ...   \n",
       "50              False               ...   \n",
       "53              False               ...   \n",
       "74              False               ...   \n",
       "\n",
       "                                         expanded_url     mention_name  \\\n",
       "5   https://edition.cnn.com/europe/live-news/russi...                    \n",
       "38                                                                       \n",
       "50  https://realcontextnews.com/moscows-1939-finla...  KyivIndependent   \n",
       "53  https://realcontextnews.com/moscows-1939-finla...                    \n",
       "74  https://realcontextnews.com/how-ukraine-can-ta...        AJEnglish   \n",
       "\n",
       "   hashtags retweet_count reply_count like_count quote_count      username  \\\n",
       "5                       6           0         33           0  IuliiaMendel   \n",
       "38                     64           4        218           3  IuliiaMendel   \n",
       "50                     13           4         36           0      bfry1981   \n",
       "53                      0           0          1           0      bfry1981   \n",
       "74                      0           1          3           0      bfry1981   \n",
       "\n",
       "   individual_or_org  category  \n",
       "5         Individual  Politics  \n",
       "38        Individual  Politics  \n",
       "50        Individual  Politics  \n",
       "53        Individual  Politics  \n",
       "74        Individual  Politics  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ab9679",
   "metadata": {},
   "source": [
    "## Test to clean ukraine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de5632d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df)=916955\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_parquet(\"./../../data/raw/ukraine_tweets_en.parquet\")\n",
    "embeddings = np.load(\"./../../data/processed/ukraine_tweets_en.parquet.npy\")\n",
    "assert(len(df) == len(embeddings))\n",
    "print(f\"{len(df)=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a3a116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_rows)=726028\n"
     ]
    }
   ],
   "source": [
    "# Select unique rows from dataset texts and corresponding embeddings\n",
    "text_column = 'text'\n",
    "unique_mask = df[text_column].map(df[text_column].value_counts()) == 1\n",
    "unique_rows = df[unique_mask]\n",
    "unique_embeddings = embeddings[unique_mask.to_numpy()]\n",
    "assert(len(unique_rows) == len(unique_embeddings))\n",
    "print(f\"{len(unique_rows)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b59775b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_rows)=726028\n"
     ]
    }
   ],
   "source": [
    "# eliminate zero length strings\n",
    "nonzero_mask = unique_rows[text_column].str.len()>0\n",
    "assert(len(nonzero_mask) == len(unique_rows))\n",
    "assert(len(nonzero_mask) == len(unique_embeddings))\n",
    "\n",
    "unique_rows = unique_rows[nonzero_mask]\n",
    "unique_embeddings = unique_embeddings[nonzero_mask.to_numpy()]\n",
    "\n",
    "unique_texts = unique_rows[text_column]\n",
    "assert(len(unique_rows) == len(unique_embeddings))\n",
    "print(f\"{len(unique_rows)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfde1e9",
   "metadata": {},
   "source": [
    "## Test relative validity score from gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad5ef60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_cluster_size=5, approx validity: 0.810\n",
      "min_cluster_size=5, approx validity: 0.810\n",
      "min_cluster_size=5, approx validity: 0.809\n",
      "min_cluster_size=10, approx validity: 0.809\n",
      "min_cluster_size=10, approx validity: 0.810\n",
      "min_cluster_size=10, approx validity: 0.809\n",
      "min_cluster_size=15, approx validity: 0.810\n",
      "min_cluster_size=15, approx validity: 0.810\n",
      "min_cluster_size=15, approx validity: 0.809\n",
      "min_cluster_size=20, approx validity: 0.811\n",
      "min_cluster_size=20, approx validity: 0.810\n",
      "min_cluster_size=20, approx validity: 0.809\n",
      "\n",
      "Best approx relative validity score: 0.8108249518581392\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import HDBSCAN\n",
    "import numpy as np\n",
    "\n",
    "def approximate_relative_validity(X, clusterer):\n",
    "    labels = clusterer.labels_\n",
    "    mask = labels != -1\n",
    "\n",
    "    # Require at least 2 clusters (not including noise)\n",
    "    n_clusters = len(set(labels[mask]))\n",
    "    if n_clusters < 2:\n",
    "        return 0.0\n",
    "\n",
    "    try:\n",
    "        score = silhouette_score(X[mask], labels[mask])\n",
    "        return score\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "# Generate synthetic data\n",
    "X, _ = make_blobs(n_samples=3000, centers=10, cluster_std=0.5, random_state=42)\n",
    "\n",
    "# Try several parameter settings\n",
    "best_score = -1\n",
    "best_clusterer = None\n",
    "\n",
    "for min_cluster_size in [5, 10, 15, 20]:\n",
    "    for min_samples in [None, 5, 10]:\n",
    "        clusterer = HDBSCAN(min_cluster_size=min_cluster_size, min_samples=min_samples).fit(X)\n",
    "        score = approximate_relative_validity(X, clusterer)\n",
    "        print(f\"min_cluster_size={min_cluster_size}, approx validity: {score:.3f}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_clusterer = clusterer\n",
    "\n",
    "print(\"\\nBest approx relative validity score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0373542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fast_hdbscan\n",
    "import numpy as np\n",
    "\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for min_cluster_size in [5, 10, 20, 30]:\n",
    "    for min_samples in [None, 5, 10]:\n",
    "        clusterer = fast_hdbscan.HDBSCAN(min_cluster_size=min_cluster_size,\n",
    "                                         min_samples=min_samples,\n",
    "                                         )\n",
    "        labels = clusterer.fit_predict(X)\n",
    "        if len(set(labels)) > 1:  # skip single-cluster or all-noise\n",
    "            score = silhouette_score(X, labels)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = (min_cluster_size, min_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccae7cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 500 samples with 2 features.\n",
      "Original cluster distribution (true labels): (array([0, 1, 2, 3]), array([125, 125, 125, 125]))\n",
      "\n",
      "Running HDBSCAN clustering...\n",
      "HDBSCAN found 4 clusters (excluding noise).\n",
      "Cluster labels assigned: (array([-1,  0,  1,  2,  3]), array([  4, 125, 125, 124, 122]))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MinimumSpanningTree' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# --- 3. Access the Minimum Spanning Tree (MST) ---\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# The `minimum_spanning_tree_` attribute contains the MST used for hierarchy construction.\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# It's a Pandas DataFrame with 'source', 'target', and 'weight' columns.\u001b[39;00m\n\u001b[32m     40\u001b[39m mst = clusterer.minimum_spanning_tree_\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mMinimum Spanning Tree (first 5 edges):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhead\u001b[49m()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal number of edges in MST: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(mst)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# --- 4. Compute Relative Validity for each Cluster ---\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'MinimumSpanningTree' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "import fast_hdbscan as hdbscan # fast_hdbscan is typically imported as hdbscan\n",
    "import pandas as pd # Used for convenient DataFrame operations with the MST\n",
    "\n",
    "# --- Configuration ---\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- 1. Generate Synthetic Data ---\n",
    "# Create a dataset with distinct clusters\n",
    "n_samples = 500\n",
    "n_features = 2\n",
    "centers = [[0, 0], [2, 2], [-2, 2], [0, -3]]\n",
    "cluster_std = [0.4, 0.5, 0.5, 0.3] # Standard deviation of each cluster\n",
    "X, y_true = make_blobs(n_samples=n_samples, centers=centers, cluster_std=cluster_std, random_state=42)\n",
    "\n",
    "print(f\"Generated {n_samples} samples with {n_features} features.\")\n",
    "print(f\"Original cluster distribution (true labels): {np.unique(y_true, return_counts=True)}\")\n",
    "\n",
    "# --- 2. Apply fast_hdbscan ---\n",
    "# Initialize and fit the HDBSCAN model\n",
    "# min_cluster_size: The smallest size a cluster can be.\n",
    "# min_samples: The number of neighbors around a point to consider it as a core point.\n",
    "#              Larger values lead to more conservative clustering.\n",
    "print(\"\\nRunning HDBSCAN clustering...\")\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=15, min_samples=5, allow_single_cluster=True, store_data=True)\n",
    "clusterer.fit(X)\n",
    "\n",
    "# Get the cluster labels for each point\n",
    "# -1 indicates noise points\n",
    "labels = clusterer.labels_\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "print(f\"HDBSCAN found {n_clusters} clusters (excluding noise).\")\n",
    "print(f\"Cluster labels assigned: {np.unique(labels, return_counts=True)}\")\n",
    "\n",
    "# --- 3. Access the Minimum Spanning Tree (MST) ---\n",
    "# The `minimum_spanning_tree_` attribute contains the MST used for hierarchy construction.\n",
    "# It's a Pandas DataFrame with 'source', 'target', and 'weight' columns.\n",
    "mst = clusterer.minimum_spanning_tree_\n",
    "\n",
    "print(f\"\\nMinimum Spanning Tree (first 5 edges):\\n{mst.head()}\")\n",
    "print(f\"Total number of edges in MST: {len(mst)}\")\n",
    "\n",
    "# --- 4. Compute Relative Validity for each Cluster ---\n",
    "\n",
    "def calculate_relative_validity(cluster_id, data_labels, mst_df):\n",
    "    \"\"\"\n",
    "    Calculates a 'relative validity' score for a given cluster based on its\n",
    "    internal and external MST edge weights.\n",
    "\n",
    "    Args:\n",
    "        cluster_id (int): The ID of the cluster to evaluate.\n",
    "        data_labels (np.ndarray): Array of cluster labels for each data point.\n",
    "        mst_df (pd.DataFrame): DataFrame representing the Minimum Spanning Tree,\n",
    "                               with 'source', 'target', and 'weight' columns.\n",
    "\n",
    "    Returns:\n",
    "        float: The relative validity score for the cluster.\n",
    "               Returns 0.0 if no internal or external edges are found, or in case\n",
    "               of division by zero (e.g., no internal edges).\n",
    "    \"\"\"\n",
    "    # Get indices of points belonging to the current cluster\n",
    "    cluster_points_indices = np.where(data_labels == cluster_id)[0]\n",
    "\n",
    "    if len(cluster_points_indices) == 0:\n",
    "        return 0.0 # No points in this cluster\n",
    "\n",
    "    internal_edge_weights = []\n",
    "    external_edge_weights = []\n",
    "\n",
    "    for _, row in mst_df.iterrows():\n",
    "        source = row['source']\n",
    "        target = row['target']\n",
    "        weight = row['weight']\n",
    "\n",
    "        is_source_in_cluster = source in cluster_points_indices\n",
    "        is_target_in_cluster = target in cluster_points_indices\n",
    "\n",
    "        if is_source_in_cluster and is_target_in_cluster:\n",
    "            # Both points are in the current cluster -> Internal edge\n",
    "            internal_edge_weights.append(weight)\n",
    "        elif is_source_in_cluster != is_target_in_cluster:\n",
    "            # One point is in the cluster, the other is outside -> External edge\n",
    "            external_edge_weights.append(weight)\n",
    "\n",
    "    max_internal_weight = 0.0\n",
    "    if internal_edge_weights:\n",
    "        max_internal_weight = max(internal_edge_weights)\n",
    "    else:\n",
    "        # If there are no internal edges (e.g., singleton cluster or very sparse connectivity),\n",
    "        # consider its internal \"tightness\" as infinite, leading to a validity of 0 or undefined.\n",
    "        # For this metric, we'll assign a very small value to avoid division by zero\n",
    "        # or indicate poor internal cohesion.\n",
    "        # A cluster without internal edges (connecting its own members) is poorly formed.\n",
    "        print(f\"  Warning: Cluster {cluster_id} has no internal MST edges. Max internal weight set to a small value.\")\n",
    "        max_internal_weight = 1e-9 # Prevent division by zero, indicates poor internal cohesion\n",
    "\n",
    "    min_external_weight = float('inf')\n",
    "    if external_edge_weights:\n",
    "        min_external_weight = min(external_edge_weights)\n",
    "    else:\n",
    "        # If there are no external edges, the cluster is perfectly isolated.\n",
    "        # This is a very strong cluster, so assign a very high value.\n",
    "        print(f\"  Info: Cluster {cluster_id} has no external MST edges. Min external weight set to infinity.\")\n",
    "        return float('inf')\n",
    "\n",
    "    # Calculate relative validity\n",
    "    # A higher score means better separation (larger min_external)\n",
    "    # and tighter internal cohesion (smaller max_internal).\n",
    "    relative_validity = min_external_weight / max_internal_weight\n",
    "\n",
    "    return relative_validity\n",
    "\n",
    "print(\"\\n--- Calculating Relative Validity for each cluster ---\")\n",
    "relative_validity_scores = {}\n",
    "for cluster_id in sorted(np.unique(labels)):\n",
    "    if cluster_id == -1:\n",
    "        # Skip noise points as they don't form a coherent cluster\n",
    "        continue\n",
    "\n",
    "    score = calculate_relative_validity(cluster_id, labels, mst)\n",
    "    relative_validity_scores[cluster_id] = score\n",
    "    print(f\"Cluster {cluster_id}: Relative Validity = {score:.4f}\")\n",
    "\n",
    "print(\"\\n--- Summary of Relative Validity Scores ---\")\n",
    "if relative_validity_scores:\n",
    "    for cluster_id, score in sorted(relative_validity_scores.items()):\n",
    "        print(f\"Cluster {cluster_id}: {score:.4f}\")\n",
    "else:\n",
    "    print(\"No clusters found (or only noise).\")\n",
    "\n",
    "# --- Visualizing MST and Clusters (Optional, for better understanding) ---\n",
    "# This part requires matplotlib to be installed.\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scipy.sparse import coo_matrix\n",
    "    from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "\n",
    "    print(\"\\n--- Visualizing MST and Clusters ---\")\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Plot data points, colored by cluster\n",
    "    unique_labels = np.unique(labels)\n",
    "    colors = plt.cm.get_cmap('Spectral', len(unique_labels))\n",
    "    for k, col in zip(unique_labels, colors(np.linspace(0, 1, len(unique_labels)))):\n",
    "        if k == -1:\n",
    "            # Black used for noise.\n",
    "            col = [0, 0, 0, 1]\n",
    "\n",
    "        class_member_mask = (labels == k)\n",
    "        xy = X[class_member_mask]\n",
    "        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "                 markeredgecolor='k', markersize=6, label=f'Cluster {k}')\n",
    "\n",
    "    # Plot MST edges\n",
    "    # Filter MST edges for visualization (e.g., only show edges with weight below a threshold)\n",
    "    # This helps to avoid clutter for very large datasets\n",
    "    # You might want to adjust this threshold or remove it based on your data\n",
    "    # For simplicity, let's plot all edges for now\n",
    "    for _, row in mst.iterrows():\n",
    "        source_idx = row['source']\n",
    "        target_idx = row['target']\n",
    "        weight = row['weight']\n",
    "\n",
    "        # Get coordinates of source and target points\n",
    "        p1 = X[source_idx]\n",
    "        p2 = X[target_idx]\n",
    "\n",
    "        # Draw a line between them\n",
    "        # You can color-code edges if you want to distinguish internal/external\n",
    "        plt.plot([p1[0], p2[0]], [p1[1], p2[1]], 'grey', linewidth=0.5, alpha=0.6)\n",
    "\n",
    "\n",
    "    plt.title('HDBSCAN Clustering with MST Edges')\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "except ImportError:\n",
    "    print(\"\\nMatplotlib not installed. Skipping visualization.\")\n",
    "    print(\"To install: pip install matplotlib\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "767e52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fast_hdbscan as fast_hdbscan\n",
    "import hdbscan as hdbscan\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X = np.load('./../../data/processed/cop26_tweets_en.parquet.npy')\n",
    "X = X[:1000]\n",
    "\n",
    "\n",
    "data, _ = make_blobs(1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf19e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = -np.inf\n",
    "best_params = None\n",
    "#X_reduced = umap_model.fit(X)\n",
    "for min_cluster_size in [5, 10, 20, 30]:\n",
    "    for cluster_selection_method in ['leaf','eom']:\n",
    "        clusterer = fast_hdbscan.HDBSCAN(min_cluster_size=min_cluster_size,\n",
    "                                         cluster_selection_method=cluster_selection_method,\n",
    "                                         )\n",
    "        labels = clusterer.fit_predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4c178c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clusterer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhdbscan\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validity_index\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m labels = \u001b[43mclusterer\u001b[49m.fit_predict(data)\n\u001b[32m      3\u001b[39m validity_index(data, labels)\n",
      "\u001b[31mNameError\u001b[39m: name 'clusterer' is not defined"
     ]
    }
   ],
   "source": [
    "from hdbscan import validity_index\n",
    "labels = clusterer.fit_predict(data)\n",
    "validity_index(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65d4b303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced = umap_model.fit_transform(X)\n",
    "best_validity = -float('Inf')\n",
    "X_reduced.shape\n",
    "#clusterer.fit_predict(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f7189202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_cluster_size=10, cluster_selection_method='leaf',curr_validity=np.float64(0.4280920920455761), noise=0.271, n_clusters=29\n",
      "min_cluster_size=10, cluster_selection_method='eom',curr_validity=np.float64(0.42473240397814277), noise=0.247, n_clusters=27\n",
      "min_cluster_size=15, cluster_selection_method='leaf',curr_validity=np.float64(0.3706763289696604), noise=0.389, n_clusters=20\n",
      "min_cluster_size=15, cluster_selection_method='eom',curr_validity=np.float64(0.8502696934575713), noise=0.0, n_clusters=2\n",
      "min_cluster_size=30, cluster_selection_method='leaf',curr_validity=np.float64(0.12244389530367211), noise=0.726, n_clusters=5\n",
      "min_cluster_size=30, cluster_selection_method='eom',curr_validity=np.float64(0.25436919508650147), noise=0.406, n_clusters=2\n",
      "min_cluster_size=10, cluster_selection_method='leaf',curr_validity=np.float64(0.291613516912397), noise=0.462, n_clusters=24\n",
      "min_cluster_size=10, cluster_selection_method='eom',curr_validity=np.float64(0.6589600258299887), noise=0.0, n_clusters=2\n",
      "min_cluster_size=15, cluster_selection_method='leaf',curr_validity=np.float64(0.2327658545504467), noise=0.508, n_clusters=14\n",
      "min_cluster_size=15, cluster_selection_method='eom',curr_validity=np.float64(0.6589600258299887), noise=0.0, n_clusters=2\n",
      "min_cluster_size=30, cluster_selection_method='leaf',curr_validity=np.float64(0.1864200806501066), noise=0.696, n_clusters=6\n",
      "min_cluster_size=30, cluster_selection_method='eom',curr_validity=np.float64(0.3843860979575009), noise=0.19, n_clusters=2\n",
      "min_cluster_size=10, cluster_selection_method='leaf',curr_validity=np.float64(0.4177919116337411), noise=0.28, n_clusters=29\n",
      "min_cluster_size=10, cluster_selection_method='eom',curr_validity=np.float64(0.4114719775373198), noise=0.265, n_clusters=28\n",
      "min_cluster_size=15, cluster_selection_method='leaf',curr_validity=np.float64(0.34464291331851776), noise=0.387, n_clusters=21\n",
      "min_cluster_size=15, cluster_selection_method='eom',curr_validity=np.float64(0.8079667903148614), noise=0.0, n_clusters=2\n",
      "min_cluster_size=30, cluster_selection_method='leaf',curr_validity=np.float64(0.16002925088920086), noise=0.672, n_clusters=6\n",
      "min_cluster_size=30, cluster_selection_method='eom',curr_validity=np.float64(0.2901148548417472), noise=0.114, n_clusters=2\n",
      "min_cluster_size=10, cluster_selection_method='leaf',curr_validity=np.float64(0.3159896696011099), noise=0.415, n_clusters=23\n",
      "min_cluster_size=10, cluster_selection_method='eom',curr_validity=np.float64(0.6732913501983384), noise=0.0, n_clusters=2\n",
      "min_cluster_size=15, cluster_selection_method='leaf',curr_validity=np.float64(0.27620411828450947), noise=0.498, n_clusters=15\n",
      "min_cluster_size=15, cluster_selection_method='eom',curr_validity=np.float64(0.6732913501983384), noise=0.0, n_clusters=2\n",
      "min_cluster_size=30, cluster_selection_method='leaf',curr_validity=np.float64(0.19985934283201773), noise=0.671, n_clusters=6\n",
      "min_cluster_size=30, cluster_selection_method='eom',curr_validity=np.float64(0.1762900897590268), noise=0.506, n_clusters=3\n",
      "min_cluster_size=10, cluster_selection_method='leaf',curr_validity=np.float64(0.3846607250019873), noise=0.297, n_clusters=29\n",
      "min_cluster_size=10, cluster_selection_method='eom',curr_validity=np.float64(0.39169883404112943), noise=0.278, n_clusters=28\n",
      "min_cluster_size=15, cluster_selection_method='leaf',curr_validity=np.float64(0.35860356281347794), noise=0.432, n_clusters=20\n",
      "min_cluster_size=15, cluster_selection_method='eom',curr_validity=np.float64(0.7800032290343537), noise=0.0, n_clusters=2\n",
      "min_cluster_size=30, cluster_selection_method='leaf',curr_validity=np.float64(0.1319839672518439), noise=0.669, n_clusters=6\n",
      "min_cluster_size=30, cluster_selection_method='eom',curr_validity=np.float64(0.3360034478874374), noise=0.152, n_clusters=2\n",
      "min_cluster_size=10, cluster_selection_method='leaf',curr_validity=np.float64(0.29449967201069877), noise=0.473, n_clusters=25\n",
      "min_cluster_size=10, cluster_selection_method='eom',curr_validity=np.float64(0.6430979861082744), noise=0.0, n_clusters=2\n",
      "min_cluster_size=15, cluster_selection_method='leaf',curr_validity=np.float64(0.28885351019662264), noise=0.521, n_clusters=12\n",
      "min_cluster_size=15, cluster_selection_method='eom',curr_validity=np.float64(0.6430979861082744), noise=0.0, n_clusters=2\n",
      "min_cluster_size=30, cluster_selection_method='leaf',curr_validity=np.float64(0.14030184055301437), noise=0.672, n_clusters=5\n",
      "min_cluster_size=30, cluster_selection_method='eom',curr_validity=np.float64(0.14030184055301437), noise=0.672, n_clusters=5\n",
      "min_cluster_size=10, cluster_selection_method='leaf',curr_validity=np.float64(0.4332658974713412), noise=0.311, n_clusters=29\n",
      "min_cluster_size=10, cluster_selection_method='eom',curr_validity=np.float64(0.4378683506824968), noise=0.281, n_clusters=27\n",
      "min_cluster_size=15, cluster_selection_method='leaf',curr_validity=np.float64(0.3745257526580453), noise=0.397, n_clusters=20\n",
      "min_cluster_size=15, cluster_selection_method='eom',curr_validity=np.float64(0.1749026335511676), noise=0.041, n_clusters=6\n",
      "min_cluster_size=30, cluster_selection_method='leaf',curr_validity=np.float64(0.15768239091784159), noise=0.665, n_clusters=6\n",
      "min_cluster_size=30, cluster_selection_method='eom',curr_validity=np.float64(0.25259969333896765), noise=0.106, n_clusters=2\n",
      "min_cluster_size=10, cluster_selection_method='leaf',curr_validity=np.float64(0.33006221849856693), noise=0.4, n_clusters=22\n",
      "min_cluster_size=10, cluster_selection_method='eom',curr_validity=np.float64(0.7832945799567416), noise=0.0, n_clusters=2\n",
      "min_cluster_size=15, cluster_selection_method='leaf',curr_validity=np.float64(0.2650282545249993), noise=0.512, n_clusters=14\n",
      "min_cluster_size=15, cluster_selection_method='eom',curr_validity=np.float64(0.7832945799567416), noise=0.0, n_clusters=2\n",
      "min_cluster_size=30, cluster_selection_method='leaf',curr_validity=np.float64(0.10161159604234171), noise=0.688, n_clusters=5\n",
      "min_cluster_size=30, cluster_selection_method='eom',curr_validity=np.float64(0.11395519097199339), noise=0.664, n_clusters=4\n",
      "Best Parameters: {'n_neighbors': 15, 'n_components': 5, 'min_cluster_size': 15, 'cluster_selection_method': 'eom'}\n",
      "Best Validity: 0.8502696934575713\n",
      "noise=0.664, n_clusters=4\n"
     ]
    }
   ],
   "source": [
    "best_params = {}\n",
    "best_validity = -float('Inf')\n",
    "\n",
    "for n_components in [5,15,30, 50]:\n",
    "    for n_neighbors in [15, 50]:\n",
    "        reduction_model = UMAP(n_neighbors=n_neighbors, n_components=n_neighbors, metric='cosine', n_jobs=-1)\n",
    "        X_reduced = reduction_model.fit_transform(X)\n",
    "        for min_cluster_size in [10, 15, 30]:\n",
    "            for cluster_selection_method in ['leaf','eom']:\n",
    "                clusterer = fast_hdbscan.HDBSCAN(min_cluster_size=min_cluster_size,\n",
    "                                            cluster_selection_method=cluster_selection_method,\n",
    "                                            )\n",
    "                labels = clusterer.fit_predict(X_reduced)\n",
    "                noise = len(np.where(labels==-1)[0])/len(labels)\n",
    "                n_clusters = len(np.unique(labels))-1\n",
    "\n",
    "                curr_validity = validity_index(X_reduced.astype(np.float64), labels, metric='euclidean')\n",
    "                print(f'{min_cluster_size=}, {cluster_selection_method=},{curr_validity=}, {noise=}, {n_clusters=}')\n",
    "                if best_validity < curr_validity:\n",
    "                    best_validity = curr_validity\n",
    "                    best_params['n_neighbors'] = n_neighbors\n",
    "                    best_params['n_components'] = n_components\n",
    "                    best_params['min_cluster_size'] = min_cluster_size\n",
    "                    best_params['cluster_selection_method'] = cluster_selection_method\n",
    "noise = len(np.where(labels==-1)[0])/len(labels)\n",
    "n_clusters = len(np.unique(labels))-1\n",
    "print(f\"Best Parameters: {best_params}\\nBest Validity: {best_validity}\")\n",
    "print(f\"{noise=}, {n_clusters=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc3794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise=0.676, n_clusters=5\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd82356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnaldo/Documents/prog-projects/complexity72_25/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/arnaldo/Documents/prog-projects/complexity72_25/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/arnaldo/Documents/prog-projects/complexity72_25/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/arnaldo/Documents/prog-projects/complexity72_25/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/arnaldo/Documents/prog-projects/complexity72_25/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/arnaldo/Documents/prog-projects/complexity72_25/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/arnaldo/Documents/prog-projects/complexity72_25/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/arnaldo/Documents/prog-projects/complexity72_25/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/arnaldo/Documents/prog-projects/complexity72_25/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/arnaldo/Documents/prog-projects/complexity72_25/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/arnaldo/Documents/prog-projects/complexity72_25/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/arnaldo/Documents/prog-projects/complexity72_25/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/arnaldo/Documents/prog-projects/complexity72_25/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/arnaldo/Documents/prog-projects/complexity72_25/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/arnaldo/Documents/prog-projects/complexity72_25/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/arnaldo/Documents/prog-projects/complexity72_25/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for min_cluster_size in [5, 10, 20, 30]:\n",
    "    for cluster_selection_method in ['leaf','eom']:\n",
    "        clusterer = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size,\n",
    "                                         cluster_selection_method=cluster_selection_method,\n",
    "                                         )\n",
    "        labels = clusterer.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "540d1003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnaldo/Documents/prog-projects/complexity72_25/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/arnaldo/Documents/prog-projects/complexity72_25/.venv/lib/python3.12/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_random_state=3640738295\n",
      "min_cluster_size=5, cluster_selection_method='leaf'\n",
      "this_reduced_validity=np.float64(0.49945804304443414)\n",
      "min_cluster_size=5, cluster_selection_method='eom'\n",
      "this_reduced_validity=np.float64(0.5108110361457783)\n",
      "min_cluster_size=10, cluster_selection_method='leaf'\n",
      "this_reduced_validity=np.float64(0.5130051115813761)\n",
      "min_cluster_size=10, cluster_selection_method='eom'\n",
      "this_reduced_validity=np.float64(0.5066864441829844)\n",
      "min_cluster_size=20, cluster_selection_method='leaf'\n",
      "this_reduced_validity=np.float64(0.3485894451356984)\n",
      "min_cluster_size=20, cluster_selection_method='eom'\n",
      "this_reduced_validity=np.float64(0.3657448485834856)\n",
      "min_cluster_size=30, cluster_selection_method='leaf'\n",
      "this_reduced_validity=np.float64(0.16511476104767048)\n",
      "min_cluster_size=30, cluster_selection_method='eom'\n",
      "this_reduced_validity=np.float64(0.32336811056224557)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cluster\n",
    "from hdbscan import validity_index\n",
    "import numpy as np\n",
    "from umap import UMAP\n",
    "import random\n",
    "my_random_state = random.randint(0,2**32-1) # 1138341792\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "reducer = UMAP(n_neighbors=15, n_components=5, metric='cosine', n_jobs=-1, min_dist=0.0, random_state=my_random_state)\n",
    "X_reduced = reducer.fit_transform(X)\n",
    "print(f\"{my_random_state=}\")\n",
    "for min_cluster_size in [5, 10, 20, 30]:\n",
    "    for cluster_selection_method in ['leaf','eom']:\n",
    "        print(f'{min_cluster_size=}, {cluster_selection_method=}')\n",
    "        clusterer = cluster.HDBSCAN(min_cluster_size=min_cluster_size,\n",
    "                                         cluster_selection_method=cluster_selection_method,\n",
    "                                         n_jobs = -1,\n",
    "                                         )\n",
    "        labels = clusterer.fit_predict(X_reduced)\n",
    "        #this_validity = validity_index(X.astype(np.float64), labels)\n",
    "        this_reduced_validity = validity_index(X_reduced.astype(np.float64), labels)\n",
    "        \n",
    "        #print(f\"{this_validity}, {this_reduced_validity}\")\n",
    "        print(f\"{this_reduced_validity=}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
